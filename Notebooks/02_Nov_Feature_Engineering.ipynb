{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59caeb08-70d9-4db8-8e72-50a02c6b72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50f8ef2b-da0e-4526-aed6-45dc932e8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path = r\"D:\\Sparkathon\\Data\\phase1_Nov_cleaned_ecommerce_data.csv\"\n",
    "output_path = r\"D:\\Sparkathon\\Data\\phase2_Nov_session_features.csv\"\n",
    "\n",
    "# We'll accumulate rows into a temp CSV for memory efficiency\n",
    "temp_chunk_csv = r\"D:\\Sparkathon\\Data\\temp_chunked_nov_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ff5b873-26b6-4184-8e5d-45f2126aad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1...\n",
      "Processing chunk 2...\n",
      "Processing chunk 3...\n",
      "Processing chunk 4...\n",
      "Processing chunk 5...\n",
      "Processing chunk 6...\n",
      "Processing chunk 7...\n",
      "Processing chunk 8...\n",
      "Processing chunk 9...\n",
      "Processing chunk 10...\n",
      "Processing chunk 11...\n",
      "Processing chunk 12...\n",
      "Processing chunk 13...\n",
      "Processing chunk 14...\n",
      "Processing chunk 15...\n",
      "Processing chunk 16...\n",
      "Processing chunk 17...\n",
      "Processing chunk 18...\n",
      "Processing chunk 19...\n",
      "Processing chunk 20...\n",
      "Processing chunk 21...\n",
      "Processing chunk 22...\n",
      "Processing chunk 23...\n",
      "Processing chunk 24...\n",
      "Processing chunk 25...\n",
      "Processing chunk 26...\n",
      "Processing chunk 27...\n",
      "Processing chunk 28...\n",
      "Processing chunk 29...\n",
      "Processing chunk 30...\n",
      "Processing chunk 31...\n",
      "Processing chunk 32...\n",
      "Processing chunk 33...\n",
      "Processing chunk 34...\n",
      "Processing chunk 35...\n",
      "Processing chunk 36...\n",
      "Processing chunk 37...\n",
      "Processing chunk 38...\n",
      "Processing chunk 39...\n",
      "Processing chunk 40...\n",
      "Processing chunk 41...\n",
      "Processing chunk 42...\n",
      "Processing chunk 43...\n",
      "Processing chunk 44...\n",
      "Processing chunk 45...\n",
      "Processing chunk 46...\n",
      "Processing chunk 47...\n",
      "Processing chunk 48...\n",
      "Processing chunk 49...\n",
      "Processing chunk 50...\n",
      "Processing chunk 51...\n",
      "Processing chunk 52...\n",
      "Processing chunk 53...\n",
      "Processing chunk 54...\n",
      "Processing chunk 55...\n",
      "Processing chunk 56...\n",
      "Processing chunk 57...\n",
      "Processing chunk 58...\n",
      "Processing chunk 59...\n",
      "Processing chunk 60...\n",
      "Processing chunk 61...\n",
      "Processing chunk 62...\n",
      "Processing chunk 63...\n",
      "Processing chunk 64...\n",
      "Processing chunk 65...\n",
      "Processing chunk 66...\n",
      "Processing chunk 67...\n",
      "Processing chunk 68...\n",
      "Processing chunk 69...\n",
      "Processing chunk 70...\n",
      "Processing chunk 71...\n",
      "Processing chunk 72...\n",
      "Processing chunk 73...\n",
      "Processing chunk 74...\n",
      "Processing chunk 75...\n",
      "Processing chunk 76...\n",
      "Processing chunk 77...\n",
      "Processing chunk 78...\n",
      "Processing chunk 79...\n",
      "Processing chunk 80...\n",
      "Processing chunk 81...\n",
      "Processing chunk 82...\n",
      "Processing chunk 83...\n",
      "Processing chunk 84...\n",
      "Processing chunk 85...\n",
      "Processing chunk 86...\n",
      "Processing chunk 87...\n",
      "Processing chunk 88...\n",
      "Processing chunk 89...\n",
      "Processing chunk 90...\n",
      "Processing chunk 91...\n",
      "Processing chunk 92...\n",
      "Processing chunk 93...\n",
      "Processing chunk 94...\n",
      "Processing chunk 95...\n",
      "Processing chunk 96...\n",
      "Processing chunk 97...\n",
      "Processing chunk 98...\n",
      "Processing chunk 99...\n",
      "Processing chunk 100...\n",
      "Processing chunk 101...\n",
      "Processing chunk 102...\n",
      "Processing chunk 103...\n",
      "Processing chunk 104...\n",
      "Processing chunk 105...\n",
      "Processing chunk 106...\n",
      "Processing chunk 107...\n",
      "Processing chunk 108...\n",
      "Processing chunk 109...\n",
      "Processing chunk 110...\n",
      "Processing chunk 111...\n",
      "Processing chunk 112...\n",
      "Processing chunk 113...\n",
      "Processing chunk 114...\n",
      "Processing chunk 115...\n",
      "Processing chunk 116...\n",
      "Processing chunk 117...\n",
      "Processing chunk 118...\n",
      "Processing chunk 119...\n",
      "Processing chunk 120...\n",
      "Processing chunk 121...\n",
      "Processing chunk 122...\n",
      "Processing chunk 123...\n",
      "Processing chunk 124...\n",
      "Processing chunk 125...\n",
      "Processing chunk 126...\n",
      "Processing chunk 127...\n",
      "Processing chunk 128...\n",
      "Processing chunk 129...\n",
      "Processing chunk 130...\n",
      "Processing chunk 131...\n",
      "Processing chunk 132...\n",
      "Processing chunk 133...\n",
      "Processing chunk 134...\n",
      "Processing chunk 135...\n",
      "Processing chunk 136...\n",
      "Processing chunk 137...\n",
      "Processing chunk 138...\n",
      "Processing chunk 139...\n",
      "Processing chunk 140...\n",
      "Processing chunk 141...\n",
      "Processing chunk 142...\n",
      "Processing chunk 143...\n",
      "Processing chunk 144...\n",
      "Processing chunk 145...\n",
      "Processing chunk 146...\n",
      "Processing chunk 147...\n",
      "Processing chunk 148...\n",
      "Processing chunk 149...\n",
      "Processing chunk 150...\n",
      "Processing chunk 151...\n",
      "Processing chunk 152...\n",
      "Processing chunk 153...\n",
      "Processing chunk 154...\n",
      "Processing chunk 155...\n",
      "Processing chunk 156...\n",
      "Processing chunk 157...\n",
      "Processing chunk 158...\n",
      "Processing chunk 159...\n",
      "Processing chunk 160...\n",
      "Processing chunk 161...\n",
      "Processing chunk 162...\n",
      "Processing chunk 163...\n",
      "Processing chunk 164...\n",
      "Processing chunk 165...\n",
      "Processing chunk 166...\n",
      "Processing chunk 167...\n",
      "Processing chunk 168...\n",
      "Processing chunk 169...\n",
      "Processing chunk 170...\n",
      "Processing chunk 171...\n",
      "Processing chunk 172...\n",
      "Processing chunk 173...\n",
      "Processing chunk 174...\n",
      "Processing chunk 175...\n",
      "Processing chunk 176...\n",
      "Processing chunk 177...\n",
      "Processing chunk 178...\n",
      "Processing chunk 179...\n",
      "Processing chunk 180...\n",
      "Processing chunk 181...\n",
      "Processing chunk 182...\n",
      "Processing chunk 183...\n",
      "Processing chunk 184...\n",
      "Processing chunk 185...\n",
      "Processing chunk 186...\n",
      "Processing chunk 187...\n",
      "Processing chunk 188...\n",
      "Processing chunk 189...\n",
      "Processing chunk 190...\n",
      "Processing chunk 191...\n",
      "Processing chunk 192...\n",
      "Processing chunk 193...\n",
      "Processing chunk 194...\n",
      "Processing chunk 195...\n",
      "Processing chunk 196...\n",
      "Processing chunk 197...\n",
      "Processing chunk 198...\n",
      "Processing chunk 199...\n",
      "Processing chunk 200...\n",
      "Processing chunk 201...\n",
      "Processing chunk 202...\n",
      "Processing chunk 203...\n",
      "Processing chunk 204...\n",
      "Processing chunk 205...\n",
      "Processing chunk 206...\n",
      "Processing chunk 207...\n",
      "Processing chunk 208...\n",
      "Processing chunk 209...\n",
      "Processing chunk 210...\n",
      "Processing chunk 211...\n",
      "Processing chunk 212...\n",
      "Processing chunk 213...\n",
      "Processing chunk 214...\n",
      "Processing chunk 215...\n",
      "Processing chunk 216...\n",
      "Processing chunk 217...\n",
      "Processing chunk 218...\n",
      "Processing chunk 219...\n",
      "Processing chunk 220...\n",
      "Processing chunk 221...\n",
      "Processing chunk 222...\n",
      "Processing chunk 223...\n",
      "Processing chunk 224...\n",
      "Processing chunk 225...\n",
      "Processing chunk 226...\n",
      "Processing chunk 227...\n",
      "Processing chunk 228...\n",
      "Processing chunk 229...\n",
      "Processing chunk 230...\n",
      "Processing chunk 231...\n",
      "Processing chunk 232...\n",
      "Processing chunk 233...\n",
      "Processing chunk 234...\n",
      "Processing chunk 235...\n",
      "Processing chunk 236...\n",
      "Processing chunk 237...\n",
      "Processing chunk 238...\n",
      "Processing chunk 239...\n",
      "Processing chunk 240...\n",
      "Processing chunk 241...\n",
      "Processing chunk 242...\n",
      "Processing chunk 243...\n",
      "Processing chunk 244...\n",
      "Processing chunk 245...\n",
      "Processing chunk 246...\n",
      "Processing chunk 247...\n",
      "Processing chunk 248...\n",
      "Processing chunk 249...\n",
      "Processing chunk 250...\n",
      "Processing chunk 251...\n",
      "Processing chunk 252...\n",
      "Processing chunk 253...\n",
      "Processing chunk 254...\n",
      "Processing chunk 255...\n",
      "Processing chunk 256...\n",
      "Processing chunk 257...\n",
      "Processing chunk 258...\n",
      "Processing chunk 259...\n",
      "Processing chunk 260...\n",
      "Processing chunk 261...\n",
      "Processing chunk 262...\n",
      "Processing chunk 263...\n",
      "Processing chunk 264...\n",
      "Processing chunk 265...\n",
      "Processing chunk 266...\n",
      "Processing chunk 267...\n",
      "Processing chunk 268...\n",
      "Processing chunk 269...\n",
      "Processing chunk 270...\n",
      "Processing chunk 271...\n",
      "Processing chunk 272...\n",
      "Processing chunk 273...\n",
      "Processing chunk 274...\n",
      "Processing chunk 275...\n",
      "Processing chunk 276...\n",
      "Processing chunk 277...\n",
      "Processing chunk 278...\n",
      "Processing chunk 279...\n",
      "Processing chunk 280...\n",
      "Processing chunk 281...\n",
      "Processing chunk 282...\n",
      "Processing chunk 283...\n",
      "Processing chunk 284...\n",
      "Processing chunk 285...\n",
      "Processing chunk 286...\n",
      "Processing chunk 287...\n",
      "Processing chunk 288...\n",
      "Processing chunk 289...\n",
      "Processing chunk 290...\n",
      "Processing chunk 291...\n",
      "Processing chunk 292...\n",
      "Processing chunk 293...\n",
      "Processing chunk 294...\n",
      "Processing chunk 295...\n",
      "Processing chunk 296...\n",
      "Processing chunk 297...\n",
      "Processing chunk 298...\n",
      "Processing chunk 299...\n",
      "Processing chunk 300...\n",
      "Processing chunk 301...\n",
      "Processing chunk 302...\n",
      "Processing chunk 303...\n",
      "Processing chunk 304...\n",
      "Processing chunk 305...\n",
      "Processing chunk 306...\n",
      "Processing chunk 307...\n",
      "Processing chunk 308...\n",
      "Processing chunk 309...\n",
      "Processing chunk 310...\n",
      "Processing chunk 311...\n",
      "Processing chunk 312...\n",
      "Processing chunk 313...\n",
      "Processing chunk 314...\n",
      "Processing chunk 315...\n",
      "Processing chunk 316...\n",
      "Processing chunk 317...\n",
      "Processing chunk 318...\n",
      "Processing chunk 319...\n",
      "Processing chunk 320...\n",
      "Processing chunk 321...\n",
      "Processing chunk 322...\n",
      "Processing chunk 323...\n",
      "Processing chunk 324...\n",
      "Processing chunk 325...\n",
      "Processing chunk 326...\n",
      "Processing chunk 327...\n",
      "Processing chunk 328...\n",
      "Processing chunk 329...\n",
      "Processing chunk 330...\n",
      "Processing chunk 331...\n",
      "Processing chunk 332...\n",
      "Processing chunk 333...\n",
      "Processing chunk 334...\n",
      "Processing chunk 335...\n",
      "Processing chunk 336...\n",
      "Processing chunk 337...\n",
      "Processing chunk 338...\n"
     ]
    }
   ],
   "source": [
    "# Clear temp file if it exists\n",
    "with open(temp_chunk_csv, 'w') as f:\n",
    "    f.write('')  # empty file\n",
    "\n",
    "chunks = pd.read_csv(\n",
    "    input_path,\n",
    "    chunksize=200_000,\n",
    "    on_bad_lines='skip',\n",
    "    encoding='utf-8',\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "first_chunk = True\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i+1}...\")\n",
    "\n",
    "    # Step 2.1: Optimize types\n",
    "    chunk['event_type'] = chunk['event_type'].astype('category')\n",
    "    chunk['brand'] = chunk['brand'].astype('category')\n",
    "    chunk['main_category'] = chunk['main_category'].astype('category')\n",
    "\n",
    "    # Step 2.2: Create interaction flags\n",
    "    chunk['is_view'] = (chunk['event_type'] == 'view').astype('int8')\n",
    "    chunk['is_cart'] = (chunk['event_type'] == 'cart').astype('int8')\n",
    "    chunk['is_remove'] = (chunk['event_type'] == 'remove_from_cart').astype('int8')\n",
    "\n",
    "    # Step 2.3: Save cleaned chunk to temp file (append mode)\n",
    "    chunk.to_csv(temp_chunk_csv, mode='a', index=False, header=first_chunk)\n",
    "    first_chunk = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cd673f0-2f67-4ae0-95f0-c2c0695c7371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 338it [32:37,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating all session features...\n",
      "Merging with labels...\n",
      "Final session-level features for Nov saved to: D:\\Sparkathon\\Data\\phase2_Nov_session_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_file = r\"D:\\Sparkathon\\Data\\temp_chunked_nov_data.csv\"\n",
    "session_features_list = []\n",
    "session_labels_dict = {}\n",
    "\n",
    "# If event_time is not parsed yet, parse it inside the loop\n",
    "chunks = pd.read_csv(input_file, chunksize=200_000, engine='python', parse_dates=['event_time'])\n",
    "\n",
    "for i, chunk in enumerate(tqdm(chunks, desc=\"Processing chunks\")):\n",
    "    # Step 1: Set categorical and flags\n",
    "    chunk['event_type'] = chunk['event_type'].astype('category')\n",
    "    chunk['brand'] = chunk['brand'].astype('category')\n",
    "    chunk['main_category'] = chunk['main_category'].astype('category')\n",
    "\n",
    "    chunk['is_view'] = (chunk['event_type'] == 'view').astype('int8')\n",
    "    chunk['is_cart'] = (chunk['event_type'] == 'cart').astype('int8')\n",
    "    chunk['is_remove'] = (chunk['event_type'] == 'remove_from_cart').astype('int8')\n",
    "\n",
    "    # Step 2: Label sessions with purchase\n",
    "    labels = chunk.groupby('user_session')['event_type'].apply(lambda x: 1 if 'purchase' in x.values else 0)\n",
    "    session_labels_dict.update(labels.to_dict())\n",
    "\n",
    "    # Step 3: Aggregation for session-level features\n",
    "    session_agg = chunk.groupby('user_session').agg(\n",
    "        user_id=('user_id', 'first'),\n",
    "        session_start=('event_time', 'min'),\n",
    "        session_end=('event_time', 'max'),\n",
    "        num_events=('event_type', 'count'),\n",
    "        num_views=('is_view', 'sum'),\n",
    "        num_carts=('is_cart', 'sum'),\n",
    "        num_remove_from_cart=('is_remove', 'sum'),\n",
    "        num_unique_products=('product_id', 'nunique'),\n",
    "        num_unique_categories=('category_id', 'nunique'),\n",
    "        avg_price=('price', 'mean'),\n",
    "        max_price=('price', 'max'),\n",
    "        min_price=('price', 'min'),\n",
    "        num_brands=('brand', 'nunique'),\n",
    "    ).reset_index()\n",
    "\n",
    "    session_features_list.append(session_agg)\n",
    "\n",
    "# Combine all chunked session features\n",
    "print(\"Concatenating all session features...\")\n",
    "session_features = pd.concat(session_features_list, ignore_index=True)\n",
    "\n",
    "# Feature engineering for time\n",
    "session_features['session_start'] = pd.to_datetime(session_features['session_start'])\n",
    "session_features['session_end'] = pd.to_datetime(session_features['session_end'])\n",
    "session_features['session_duration'] = (session_features['session_end'] - session_features['session_start']).dt.total_seconds()\n",
    "session_features['hour_of_day'] = session_features['session_start'].dt.hour\n",
    "\n",
    "# Convert label dict to Series\n",
    "session_labels = pd.Series(session_labels_dict, name='purchase_label')\n",
    "\n",
    "# Merge labels\n",
    "print(\"Merging with labels...\")\n",
    "final_df = session_features.merge(session_labels, how='left', left_on='user_session', right_index=True)\n",
    "\n",
    "# Clean up\n",
    "final_df.dropna(subset=['purchase_label'], inplace=True)\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save final output\n",
    "output_path = r\"D:\\Sparkathon\\Data\\phase2_Nov_session_features.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"Final session-level features for Nov saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792b62b-394a-45d3-9c13-711e0f332132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
